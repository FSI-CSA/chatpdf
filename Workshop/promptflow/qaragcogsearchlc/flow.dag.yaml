inputs:
  question:
    type: string
    default: How are the consolidated financial statements prepared for the company?
    is_chat_input: false
  indexType:
    type: string
    default: cogsearchvs
    is_chat_input: false
  indexNs:
    type: string
    default: 3738d6dc992c4229a5a52efe84af4d3d
    is_chat_input: false
  postBody:
    type: object
    default:
      values:
      - recordId: 0
        data:
          text: ""
          approach: rtr
          overrides:
            semantic_ranker: true
            semantic_captions: false
            top: 3
            temperature: 0
            promptTemplate: "You are an AI assistant tasked with answering questions and
              summarizing information from\ 

              \        earning call transcripts, annual reports,
              SEC filings and financial statements.

              \        Your answer should accurately capture the
              key information in the document while avoiding the omission of any
              domain-specific words.\ 

              \        Please generate a concise and comprehensive
              information that includes details such as reporting year and
              amount in millions.

              \        Ensure that it is easy to understand for
              business professionals and provides an accurate representation of
              the financial statement history.\ 

              \       \ 

              \        Please remember to use clear language and
              maintain the integrity of the original information without missing
              any important details


              \        QUESTION: {question}

              \        =========

              \        {summaries}

              \        =========

              \        "
            chainType: stuff
            tokenLength: 1000
            embeddingModelType: azureopenai
            deploymentType: gpt3516k
    is_chat_input: false
  chainType:
    type: string
    default: stuff
    is_chat_input: false
outputs:
  output:
    type: string
    reference: ${followup_questions.output}
    evaluation_only: false
    is_chat_output: false
nodes:
- name: create_llm
  type: python
  source:
    type: code
    path: create_llm.py
  inputs:
    conn: chatpdf
    overrides: ${parse_postBody.output}
  use_variants: false
- name: parse_postBody
  type: python
  source:
    type: code
    path: parse_postBody.py
  inputs:
    postBody: ${inputs.postBody}
  use_variants: false
- name: search_question_from_vectordb
  type: python
  source:
    type: package
    tool: embeddingstore.tool.vector_db_lookup.VectorDBLookup.search
  inputs:
    connection: dataaioaicg
    index_name: ${inputs.indexNs}
    text_field: content
    top_k: ${extract_topk.output}
    vector: ${embed_the_question.output}
    vector_field: contentVector
  use_variants: false
- name: extract_topk
  type: python
  source:
    type: code
    path: extract_topk.py
  inputs:
    overrides: ${parse_postBody.output}
  use_variants: false
- name: answer_the_question
  type: python
  source:
    type: code
    path: execute_langchain.py
  inputs:
    llm: ${create_llm.output}
    overrides: ${parse_postBody.output}
    promptTemplate: ${extract_prompttemplate.output}
    question: ${inputs.question}
    retrievedDocs: ${generate_prompt_context.output}
  use_variants: false
- name: followup_questions
  type: python
  source:
    type: code
    path: followup_questions.py
  inputs:
    llm: ${create_llm.output}
    modifiedAnswer: ${answer_the_question.output}
    overrides: ${parse_postBody.output}
    promptTemplate: ${extract_prompttemplate.output}
    question: ${inputs.question}
    retrievedDocs: ${generate_prompt_context.output}
  use_variants: false
- name: embed_the_question
  type: python
  source:
    type: package
    tool: promptflow.tools.embedding.embedding
  inputs:
    connection: fpdoaoaice
    deployment_name: embedding
    input: ${flow.question}
  aggregation: false
  use_variants: false
- name: extract_prompttemplate
  type: python
  source:
    type: code
    path: extract_prompttemplate.py
  inputs:
    overrides: ${parse_postBody.output}
  use_variants: false
- name: generate_prompt_context
  type: python
  source:
    type: code
    path: generate_prompt_context.py
  inputs:
    search_result: ${search_question_from_vectordb.output}
  aggregation: false
  use_variants: false
